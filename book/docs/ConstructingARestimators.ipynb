{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Constructing estimators \n",
    "------------------------\n",
    "https://en.wikipedia.org/wiki/Autoregressive_model\n",
    "\n",
    "#### Thomas Schmelzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A very common estimator is based on AR models (autoregressive)\n",
    "\n",
    "$$R_T = \\sum_{i=1}^n w_i r_{T-i}$$\n",
    "\n",
    "Predict the (unknown) return $R_T$ using the last $n$ previous returns. **Attention**: You may want to use volatility adjusted returns, apply filters etc.\n",
    " \n",
    "How to pick the $n$ free parameters in $\\mathbf{w}$? (Partial) autocorrelations? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def convolution(ts, weights):\n",
    "    from statsmodels.tsa.filters.filtertools import convolution_filter\n",
    "    return convolution_filter(ts, weights, nsides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "r = pd.Series([1.0, -2.0, 1.0, 1.0, 1.5, 0.0, 2.0])\n",
    "weights = [2.0, 1.0]\n",
    "# trendfollowing == positive weights\n",
    "x=pd.DataFrame()\n",
    "x[\"r\"] = r\n",
    "x[\"pred\"] = convolution(r, weights)\n",
    "x[\"before\"] = x[\"pred\"].shift(1)\n",
    "print(x)\n",
    "print(x.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# mean-reversion == negative weights\n",
    "r = pd.Series([1.0, -2.0, 1.0, 1.0, 1.5, 0.0, 2.0])\n",
    "weights = [-2.0, -1.0]\n",
    "x=pd.DataFrame()\n",
    "x[\"r\"] = r\n",
    "x[\"pred\"] = convolution(r, weights)\n",
    "x[\"before\"] = x[\"pred\"].shift(1)\n",
    "print(x)\n",
    "print(x.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Looking only at the last two returns might be a bit ...\n",
    "\n",
    "Is it a good idea to have $n=200$ free parameters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.tsa.stattools as sts\n",
    "# generate random returns\n",
    "r = pd.read_csv(\"data/SPX_Index.csv\", squeeze=True, index_col=0, parse_dates=True).pct_change().dropna()\n",
    "# let's compute the optimal convolution!\n",
    "weights = sts.pacf(r, nlags=200)\n",
    "pd.Series(data=weights[1:]).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The trading system! \n",
    "pos = convolution(r, weights[1:])\n",
    "pos = 1e6*(pos/pos.std())\n",
    "# profit = return[today] * position[yesterday]\n",
    "(r*pos.shift(1)).cumsum().plot()\n",
    "plt.xlabel('Time'), plt.ylabel('Profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias\n",
    "----\n",
    "\n",
    "We assume the weights are exponentially decaying, e.g.\n",
    "\n",
    "$$w_i = \\frac{1}{S}\\lambda^i$$\n",
    "\n",
    "where $S$ is a suitable scaling constant and $\\lambda = 1-1/N$. Note that $N \\neq n$.\n",
    "\n",
    "**Everything** that is **not** an exponentially weighted moving average is **wrong**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def exp_weights(m, n=100):\n",
    "    x = np.power(1.0 - 1.0/m, range(1,n+1))\n",
    "    S = np.linalg.norm(x)\n",
    "    return x/S\n",
    "\n",
    "pd.Series(exp_weights(m=16,n=40)).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "periods = [2,4,6,8,12,16,24,32,48,64,96,192]\n",
    "# matrix of weights\n",
    "W = pd.DataFrame({period : exp_weights(m=period, n=200) for period in periods}) \n",
    "W.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# each column of A is a convoluted return time series\n",
    "A = pd.DataFrame({period : convolution(r, W[period]).shift(1) for period in periods})  \n",
    "\n",
    "A = A.dropna(axis=0)\n",
    "r = r[A.index].dropna()\n",
    "\n",
    "A[[2,16,64]].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(Naive) regression\n",
    "-------------------\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{w}^{*}=\\arg\\min_{\\mathbf{w} \\in \\mathbb{R}^m}& \\rVert{\\mathbf{A}\\mathbf{w} - \\mathbf{r}}\\lVert_2 \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import lstsq\n",
    "# sometimes you don't need to use MOSEK :-)\n",
    "weights = pd.Series(index=periods, data=lstsq(A.values, r.values)[0])\n",
    "print(weights)\n",
    "(W*weights).sum(axis=1).plot(kind=\"bar\")\n",
    "(W*weights).sum(axis=1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean variation\n",
    "\n",
    "We provide a few indicators. Avoid fast indicators. Prefer slower indicators as they induce less trading costs.\n",
    "Use the mean variation of the signal (convoluted returns here)\n",
    "\n",
    "$$f(\\mathbf{x}) = \\frac{1}{n}\\sum{\\lvert x_i - x_{i-1}\\rvert}=\\frac{1}{n}\\rVert{\\Delta \\mathbf{x}}\\lVert_1$$\n",
    "\n",
    "The $i$th column of $\\mathbf{A}$ has a mean variation $d_i$. We introduce the diagonal penalty matrix $\\mathbf{D}$ with $D_{i,i}=d_i$.\n",
    "\n",
    "$$\\mathbf{w}^{*}=\\arg\\min_{\\mathbf{w} \\in \\mathbb{R}^m} \\lVert{\\mathbf{Aw}-\\mathbf{r}}\\rVert_2 + \\lambda \\rVert{\\mathbf{Dw}}\\lVert_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from cvx.util import cvx, minimize\n",
    "\n",
    "def mean_variation(ts):\n",
    "    return ts.diff().abs().mean()\n",
    "    \n",
    "def ar(A, r, lamb=0.0):\n",
    "    # introduce the variable for the var\n",
    "    x = cvx.Variable(A.shape[1])  \n",
    "    D = np.diag(A.apply(mean_variation))\n",
    "    minimize(objective=cvx.norm(A.values*x-r,2) + lamb*cvx.norm(D*x,1))\n",
    "    return pd.Series(index=A.keys(), data=x.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "t_weight = pd.DataFrame({lamb : (W*ar(A, r.values, lamb=lamb)).sum(axis=1) for lamb in [0.0, 1.0, 2.0, 3.0, 5.0, 7.0, 9.0, 12.0, 15.0]})\n",
    "t_weight[[0.0,5.0,15.0]].plot(figsize=(30,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#for lamb in sorted(t_weight.keys()):\n",
    "\n",
    "pos = pd.DataFrame({lamb : convolution(r, t_weight[lamb]) for lamb in t_weight.keys()})\n",
    "pos = 1e6*(pos/pos.std())\n",
    "\n",
    "profit = pd.DataFrame({lamb : (r*pos[lamb].shift(1)).cumsum() for lamb in pos.keys()})\n",
    "profit[[0.0, 5.0, 15.0]].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- The problem of constructing an estimator is corresponds to tracking an index. The index is here a historic return time series. The **assets** are standard estimators. \n",
    "\n",
    "\n",
    "- Using the (mean) total variation of the signals can help to prefer slower signals rather than expensive fast signals.\n",
    "\n",
    "\n",
    "- Using a penalty induced by the $1$-norm (see LARS, LASSO) it is possible to establish a ranking amongst the indicators and construct them robustly. \n",
    "\n",
    "\n",
    "- It is possible to (vertical) stack the resulting systems to find optimal weights across a group of assets."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
